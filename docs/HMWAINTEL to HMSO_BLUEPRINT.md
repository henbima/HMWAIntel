# HMSO_BLUEPRINT.md
# HMSO â€” HollyMart Signal Operations â€” Complete Context Document

> **INSTRUKSI UNTUK AI (Claude Code / Cursor):**
> Baca dokumen ini SELURUHNYA sebelum menulis kode apapun.
> Dokumen ini adalah "North Star" untuk project ini.
> Semua keputusan arsitektur sudah final â€” JANGAN suggest alternatif kecuali diminta.
> Jika ada ambiguitas, rujuk ke bagian "Decisions Already Made" di bawah.

---

## 0) PROJECT IDENTITY

- **Nama project:** HMSO â€” HollyMart Signal Operations
- **Internal codename (database schema):** `wa_intel` (legacy name, may migrate to `hmso` later)
- **Owner:** Hendra Rusly â€” CEO & Lead Developer, HollyMart
- **Status:** âœ… OPERATIONAL â€” Listener running 24/7 on VPS (Biznet NEO Lite), 18,500+ messages captured, 299 groups synced, 11,900+ contacts auto-discovered.

### One-liner
The organizational nervous system that captures, classifies, and routes actionable signals from every communication channel across HollyMart.

### What It Does
HMSO transforms unstructured communication â€” WhatsApp messages across 250+ groups, meeting transcripts, and future channels â€” into structured, actionable intelligence. It listens to the entire organization in real-time, separates signal from noise, and ensures that no task, directive, or decision falls through the cracks.

### Why It Exists
HollyMart operates across multiple cities (Bima, Dompu, Lombok) with hundreds of WhatsApp groups and regular coordination meetings. Critical directives, tasks, and decisions get buried in daily chatter or lost in people's memory. When staff rotate or resign, institutional knowledge disappears with them. HMSO solves this by making organizational communication captured, classified, searchable, and accountable â€” in line with HOS v1 Â§6: "If it's not written, it didn't happen."

### Core Pipeline
1. **Capture** â†’ Ingest raw communication from all sources (WhatsApp via Baileys, Zoom transcripts via n8n, future: email, HMCS notes)
2. **Classify** â†’ AI-powered categorization of every message: tasks, directives, decisions, escalations, or routine chatter
3. **Surface** â†’ Deliver daily executive briefings, power a real-time dashboard, and enable natural language search across all organizational communication
4. **Archive** â†’ Build a persistent, searchable knowledge base that survives personnel changes and preserves institutional memory

### How It Fits the HM Ecosystem

| System | Function |
|---|---|
| **HMCS** | Runs the operation (Central System) |
| **HMLS** | Trains the people (Learning System) |
| **HMBI** | Reads the numbers (Business Intelligence) |
| **HMSO** | Hears the organization (Signal Operations) |

HMBI tells you what the data says. HMSO tells you what the people say. Together they provide complete organizational awareness.

### Design Principles
- **Source-agnostic pipeline** â€” adding a new communication channel means adding a new input, not rebuilding the system
- **AI-first classification** â€” humans review what matters, not everything
- **Zero-loss capture** â€” every message is stored, even if classified as routine, because today's chatter may be tomorrow's evidence
- **HOS v1 aligned** â€” built for compliance, repeatability, and measurable outcomes

### Hubungan dengan HMCS
HMSO dan HMCS berada di **database Supabase yang sama** (schema berbeda). HMCS sudah digunakan tim sehari-hari dan memiliki API. HMSO adalah feeder â€” data mengalir satu arah: HMSO â†’ HMCS. Tim tidak perlu tahu HMSO ada â€” mereka cukup melihat task dan briefing muncul di HMCS.

### Ini BUKAN:
chatbot, auto-reply, marketing tool, atau pengganti HMCS.

### Ini ADALAH:
Source-agnostic intelligence pipeline yang mengubah chaos komunikasi organisasi menjadi data terstruktur yang dapat di-route ke HMCS.

---

## 1) NORTH STAR & PROBLEM STATEMENT

### Masalah yang Diselesaikan

HollyMart memiliki 15+ WhatsApp group (toko Bima, Dompu, Lombok, purchasing, HO, dll). Pain points:

1. **Task tenggelam di chat** â€” Task, arahan, dan info penting tercampur dengan chit-chat dan tenggelam dalam ratusan pesan harian.
2. **Task tanpa accountability** â€” Task diberikan tapi tidak ada konfirmasi selesai. Kadang dikerjakan tanpa laporan, kadang tidak dikerjakan sama sekali.
3. **Knowledge hilang saat PIC ganti** â€” Arahan & memo panjang dari Hendra tidak ter-transfer ke orang baru dengan kualitas yang sama.
4. **Leader overwhelmed** â€” Hendra sendiri tidak mau buka WhatsApp lagi karena volume terlalu besar. Ini bottleneck.
5. **Tidak ada visibility** â€” Tidak ada dashboard atau visual overview tentang apa yang sedang terjadi di semua grup sekaligus.

### Alignment dengan HOS v1 (Hendra Operating System)

| Pain Point | HOS v1 Principle yang Dilanggar |
|---|---|
| Task tenggelam | Â§7 â€” "WA is for coordination, not operations" |
| Tidak ada accountability | Â§6 â€” "No record = no decision" / "Decision logs > verbal alignment" |
| Knowledge hilang | Â§3 â€” "Rules > Memory" â€” "If it must be remembered, it will be missed" |
| Leader bottleneck | Â§10 â€” "Decisions don't bottleneck at you" |
| Tidak ada visibility | Â§9 â€” "Measurable + Auditable" |

### 4 Kemampuan Inti (Source-Agnostic)

1. **CAPTURE** â€” Ingest raw communication dari semua sumber. WhatsApp via Baileys (read-only, nomor cadangan). Meeting transcripts via n8n/Make.com (Zoom webhook). Future: email, HMCS notes, voice memos.
2. **CLASSIFY** â€” AI kategorisasi setiap pesan/segment: Task / Arahan / Keputusan / Laporan / Eskalasi / Noise. Extract entities: siapa assign ke siapa, deadline, topik. Same classifier, any source.
3. **SURFACE** â€” Daily briefing setiap pagi (WA to self) + visual dashboard (kanban, activity, search) + chat-with-data (AI Q&A). HMCS integration for team delivery.
4. **ARCHIVE** â€” Knowledge base yang searchable. Arahan, keputusan rapat, & memo tersimpan permanen. Onboarding orang baru = instant. Personnel changes don't destroy institutional memory.

---

## 2) DECISIONS ALREADY MADE (FINAL â€” DO NOT CHANGE)

Berikut keputusan arsitektur yang sudah diambil melalui diskusi mendalam. JANGAN suggest alternatif.

| Keputusan | Pilihan | Alasan |
|---|---|---|
| **Project name** | HMSO â€” HollyMart Signal Operations | Source-agnostic. Part of HM ecosystem (HMCS, HMLS, HMBI, HMSO). |
| **Database schema** | `wa_intel` (legacy, may migrate to `hmso` later) | Schema sudah ada dan operational. Rename nanti. Kode boleh pakai alias/constant. |
| **Pipeline design** | Source-agnostic: Capture â†’ Classify â†’ Surface â†’ Archive | Adding new input source = adding new ingestion module, NOT rebuilding pipeline. |
| **WA Gateway** | Baileys (@whiskeysockets/baileys) | Open source, TypeScript, no browser needed, community besar |
| **Meeting transcript ingestion** | n8n (self-hosted on VPS) or Make.com | Zoom webhook â†’ chunk transcript â†’ AI summarize â†’ INSERT to database. n8n preferred (already have VPS). |
| **Meeting transcript AI** | Premium model via OpenRouter (Claude Sonnet / GPT-4o) | Meeting summaries need high quality. WhatsApp classification uses GPT-4o-mini (cheaper, higher volume). |
| **Meeting chunk size** | 30 minutes default, with ~2 min overlap | 15 min too granular (splits discussions). 30 min captures full topic arcs. Overlap preserves context continuity. |
| **Database** | Supabase â€” **project HMCS yang sudah ada**, schema `wa_intel` | Same database = HMCS can read directly. Zero integration cost. |
| **Baileys runner** | VPS (Biznet NEO Lite, Rp 59,000/bulan) â€” managed by PM2 | 24/7 uptime, tidak tergantung PC kantor menyala. |
| **AI Classifier** | OpenAI GPT-4o-mini (via Supabase Edge Function) | Cost efficient for high-volume WA messages. Already deployed. |
| **Dashboard** | React (built via Bolt.new) + Supabase Auth | Already deployed. Kanban, directions, contacts, groups, briefings. |
| **RAG / Knowledge Base** | PostgreSQL full-text search (Phase 1) â†’ pgvector (Phase 2) | Full-text search dulu. pgvector hanya jika perlu semantic search. |
| **Nomor WhatsApp** | Nomor cadangan / backup â€” read-only listener | Mitigasi risiko ban. Listener TIDAK mengirim pesan (kecuali 1 briefing/hari). |
| **Daily briefing delivery** | WhatsApp to self (nomor cadangan kirim ke nomor utama Hendra) | 1 pesan/hari ke diri sendiri = risiko ban negligible. |
| **Future task delivery ke tim** | Via HMCS (bukan WhatsApp bot) | HMCS sudah digunakan tim sehari-hari dan punya API. HOS Â§7 compliance. |
| **HMCS Integration** | Same database, direct read (Pattern A) â†’ API push (Pattern B) nanti | wa_intel dan HMCS di database yang sama. HMCS bisa query langsung. |
| **BUKAN OpenClaw** | Rejected | Security risk (shell access), single-user design, no dashboard. Detail: Section 16. |
| **BUKAN Periskope (SaaS)** | Rejected | Vendor dependency, $15/seat/mo, limited knowledge base. |
| **BUKAN Telegram/Email** | Rejected sebagai delivery channel | Tim tidak pakai Telegram. Jarang buka email. Operasi di WA + HMCS. |

---

## 3) ARCHITECTURE OVERVIEW

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              HMSO â€” HollyMart Signal Operations                   â”‚
â”‚              "The organizational nervous system"                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  INPUT SOURCES (Capture)                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  WhatsApp    â”‚ â”‚    Zoom      â”‚ â”‚   Future:    â”‚             â”‚
â”‚  â”‚  250+ groups â”‚ â”‚  Meetings    â”‚ â”‚  Email, HMCS â”‚             â”‚
â”‚  â”‚  (Baileys)   â”‚ â”‚  (n8n)       â”‚ â”‚  notes, etc  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                â”‚                â”‚                      â”‚
â”‚         â–¼                â–¼                â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Supabase Database â€” schema: wa_intel                 â”‚       â”‚
â”‚  â”‚  messages (source_type: 'whatsapp' | 'meeting')       â”‚       â”‚
â”‚  â”‚  meetings (full transcripts + executive summaries)    â”‚       â”‚
â”‚  â”‚  classified_items | tasks | directions                â”‚       â”‚
â”‚  â”‚  daily_briefings | contacts | groups                  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                          â”‚                                       â”‚
â”‚  INTELLIGENCE LAYER      â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Classify  â”‚ â”‚ Daily Briefing â”‚ â”‚ Chat w/   â”‚               â”‚
â”‚  â”‚ (Edge Fn) â”‚ â”‚ (pg_cron)      â”‚ â”‚ Data (AI) â”‚               â”‚
â”‚  â”‚ GPT-4o-   â”‚ â”‚                â”‚ â”‚           â”‚               â”‚
â”‚  â”‚ mini      â”‚ â”‚                â”‚ â”‚           â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                   â”‚
â”‚  OUTPUT LAYER                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Dashboard â”‚ â”‚ WhatsApp Brief â”‚ â”‚   HMCS    â”‚               â”‚
â”‚  â”‚ (React)   â”‚ â”‚ (to Hendra)    â”‚ â”‚ (team)    â”‚               â”‚
â”‚  â”‚ admin use â”‚ â”‚ 1x/day         â”‚ â”‚ API ready â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow â€” WhatsApp Source

```
[WhatsApp Groups 250+]
    â”‚
    â–¼ (Baileys WebSocket â€” nomor cadangan, READ-ONLY)
[Baileys Listener â€” VPS Biznet NEO Lite, PM2]
    â”‚
    â–¼ (INSERT with source_type='whatsapp')
[Supabase â€” wa_intel.messages]
    â”‚
    â–¼ (pg_cron every 15 min)
[AI Classifier â€” Edge Function, GPT-4o-mini]
    â”‚ â†’ classified_items, tasks, directions
    â”‚
    â”œâ”€â”€â–¶ Daily Briefing (pg_cron 7am) â†’ WhatsApp to Hendra
    â”œâ”€â”€â–¶ Dashboard (React) â†’ Kanban, search, analytics
    â”œâ”€â”€â–¶ Chat with Data (Edge Function) â†’ AI Q&A
    â””â”€â”€â–¶ HMCS (same database) â†’ team sees tasks
```

### Data Flow â€” Meeting Transcript Source

```
[Zoom Meeting Ends]
    â”‚
    â–¼ (Zoom webhook)
[n8n Workflow on VPS]
    â”‚
    â”œâ”€ 1. Receive full transcript from Zoom
    â”‚
    â”œâ”€ 2. Chunk into 30-min segments (with 2-min overlap)
    â”‚
    â”œâ”€ 3. For each chunk: AI summarize via OpenRouter (premium model)
    â”‚     Extract: decisions, tasks, directions, open questions
    â”‚
    â”œâ”€ 4. INSERT chunk summaries into wa_intel.messages
    â”‚     (source_type='meeting', meeting_metadata={...})
    â”‚
    â”œâ”€ 5. INSERT full record into wa_intel.meetings
    â”‚     (raw transcript + executive summary + metadata)
    â”‚
    â””â”€ 6. Existing pipeline takes over automatically
          Classifier â†’ Tasks â†’ Briefing â†’ Dashboard â†’ HMCS
```

### Full System Architecture (HMSO + HMCS)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           INPUT SOURCES                              â”‚
â”‚  WhatsApp (250+ groups)    Zoom Meetings             â”‚
â”‚  via Baileys (read-only)   via n8n (webhook)         â”‚
â”‚  Future: Email, HMCS notes, voice memos              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                     â”‚
               â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Supabase (shared database)                  â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  wa_intel schema  â”‚    â”‚    hmcs schema         â”‚ â”‚
â”‚  â”‚  (HMSO data)      â”‚    â”‚    (public)            â”‚ â”‚
â”‚  â”‚                   â”‚    â”‚                        â”‚ â”‚
â”‚  â”‚  messages â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â–¶â”‚  tasks (future)        â”‚ â”‚
â”‚  â”‚  meetings         â”‚    â”‚  notifications         â”‚ â”‚
â”‚  â”‚  classified_items â”‚â”€â”€â”€â–¶â”‚  employee dashboard    â”‚ â”‚
â”‚  â”‚  tasks            â”‚    â”‚                        â”‚ â”‚
â”‚  â”‚  directions       â”‚    â”‚  API available âœ…       â”‚ â”‚
â”‚  â”‚  daily_briefings  â”‚    â”‚  Team uses daily âœ…     â”‚ â”‚
â”‚  â”‚  contacts         â”‚    â”‚                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                                            â”‚
â”‚  Edge Functions:                                     â”‚
â”‚  - classify-messages (every 15 min)                  â”‚
â”‚  - generate-briefing (daily 7am)                     â”‚
â”‚  - chat-with-data (on demand)                        â”‚
â”‚  - sync-to-hmcs (future)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                          â”‚
          â–¼                          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ HMSO          â”‚        â”‚ HMCS             â”‚
   â”‚ Dashboard     â”‚        â”‚ (team daily use) â”‚
   â”‚ (Hendra/admin)â”‚        â”‚ Has API âœ…        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ WhatsApp     â”‚
   â”‚ Daily Brief  â”‚
   â”‚ (secondary â†’ â”‚
   â”‚  primary #)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


---

## 4) TECH STACK

| Layer | Technology | Version | Status | Notes |
|---|---|---|---|---|
| **INPUT: WhatsApp** | `@whiskeysockets/baileys` | v7.x | âœ… Running | Read-only listener, WebSocket-based |
| **INPUT: Meetings** | n8n (self-hosted on VPS) | Latest | ðŸ“‹ Next | Zoom webhook â†’ chunk â†’ summarize â†’ insert |
| **Meeting AI** | OpenRouter (Claude Sonnet / GPT-4o) | â€” | ðŸ“‹ Next | Premium model for long transcript summarization |
| Runtime (Baileys) | Node.js on VPS | v18+ | âœ… Running | Biznet NEO Lite, managed by PM2 |
| Database | Supabase (PostgreSQL) | Existing HMCS project | âœ… Running | Schema: `wa_intel`, 8+ tables |
| AI Classifier | GPT-4o-mini via Supabase Edge Function | â€” | âœ… Deployed | Classifies messages from ALL sources |
| Daily Briefing | Supabase Edge Function | â€” | âœ… Deployed | Generates Bahasa Indonesia summary |
| Dashboard | React + Supabase Auth | â€” | âœ… Deployed | Built via Bolt.new |
| Full-text Search | PostgreSQL tsvector/tsquery | â€” | ðŸ”œ Coming | `to_tsvector('indonesian', ...)` |
| Chat with Data | Edge Function + AI Q&A | â€” | ðŸ”œ Coming | Search â†’ context â†’ AI answer |
| HMCS Integration | Same DB direct read / HMCS API | â€” | ðŸ“‹ Planned | Pattern A (direct) â†’ Pattern B (API) |
| WA Briefing Delivery | Baileys send (secondary â†’ primary) | â€” | ðŸ“‹ Planned | 1 msg/day, negligible ban risk |
| Vector Search | Supabase pgvector | â€” | ðŸ“‹ Future | Only if full-text search insufficient |

### AI Model Strategy (Two-Tier)

| Use Case | Model | Why | Est. Cost |
|---|---|---|---|
| WhatsApp classification (high volume, short messages) | GPT-4o-mini | Cheap, fast, good enough for short texts | ~$1-3/mo |
| Meeting transcript summarization (low volume, long text) | Claude Sonnet or GPT-4o via OpenRouter | Premium quality needed for 3000-5000 word chunks | ~$2-5/mo |
| Chat-with-data Q&A | GPT-4o-mini | Short answers from retrieved context | ~$1-2/mo |
| **Total AI cost** | | | **~$4-10/mo** |

### Running Cost

| Item | Cost | Notes |
|---|---|---|
| Supabase | **$0** | Pakai project HMCS existing, schema baru |
| AI API (OpenAI + OpenRouter) | **$4-10/mo** | Two-tier: mini for WA, premium for meetings |
| VPS (Biznet NEO Lite) | **Rp 59,000/mo** | Listener + n8n, both on same VPS |
| **Total** | **~Rp 130-220k/mo** | |

### Current Metrics (as of Feb 9, 2026)

| Metric | Count |
|---|---|
| Messages captured | 18,567+ |
| Contacts auto-discovered | 11,915 |
| Groups synced | 299 |
| Group memberships | 4,906+ |
| Messages classified (test) | 30 |
| Meeting transcripts ingested | 0 (module not built yet) |

---

## 5) DATABASE SCHEMA

Semua tabel berada di schema `wa_intel` dalam Supabase project HMCS yang sudah ada.

```sql
-- ============================================
-- SCHEMA: wa_intel
-- HMSO â€” HollyMart Signal Operations System
-- ============================================

CREATE SCHEMA IF NOT EXISTS wa_intel;

-- ============================================
-- TABLE 1: groups
-- Daftar WhatsApp groups yang di-monitor
-- ============================================
CREATE TABLE wa_intel.groups (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    wa_group_id TEXT UNIQUE NOT NULL,        -- WhatsApp group JID (e.g., "120363xxx@g.us")
    name TEXT NOT NULL,                       -- Nama grup (e.g., "HollyMart Bima-1")
    description TEXT,
    is_active BOOLEAN DEFAULT true,           -- Apakah masih di-monitor
    participant_count INTEGER,
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

-- ============================================
-- TABLE 2: contacts
-- Registry orang-orang HollyMart â€” siapa mereka, apa jabatannya
-- AI classifier MEMBUTUHKAN data ini untuk konteks
-- ============================================
CREATE TABLE wa_intel.contacts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    wa_jid TEXT UNIQUE NOT NULL,              -- WhatsApp JID (e.g., "628123456789@s.whatsapp.net")
    phone_number TEXT,                        -- Nomor HP bersih (e.g., "628123456789")
    display_name TEXT NOT NULL,               -- Nama lengkap (e.g., "Budi Santoso")
    short_name TEXT,                          -- Nama panggilan (e.g., "Budi")
    role TEXT,                                -- Jabatan (e.g., "Store Manager", "Kasir", "Purchasing Staff")
    location TEXT,                            -- Lokasi (e.g., "Bima-1", "Dompu", "HO Lombok")
    department TEXT,                          -- Departemen (e.g., "Operations", "Purchasing", "HRD")
    is_leadership BOOLEAN DEFAULT false,      -- Apakah level manajerial ke atas
    is_active BOOLEAN DEFAULT true,           -- Masih aktif kerja di HollyMart
    hmcs_employee_id TEXT,                    -- (OPSIONAL) Link ke tabel karyawan di schema public (HMCS)
    notes TEXT,                               -- Catatan tambahan
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX idx_contacts_jid ON wa_intel.contacts(wa_jid);
CREATE INDEX idx_contacts_location ON wa_intel.contacts(location);

-- ============================================
-- TABLE 3: group_members
-- Siapa saja anggota tiap grup â€” many-to-many
-- ============================================
CREATE TABLE wa_intel.group_members (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    group_id UUID REFERENCES wa_intel.groups(id) ON DELETE CASCADE,
    contact_id UUID REFERENCES wa_intel.contacts(id) ON DELETE CASCADE,
    wa_role TEXT DEFAULT 'member',            -- 'admin' / 'superadmin' / 'member'
    joined_at TIMESTAMPTZ,
    is_active BOOLEAN DEFAULT true,
    UNIQUE(group_id, contact_id)
);

-- ============================================
-- TABLE 4: messages
-- Raw messages dari SEMUA sumber â€” WhatsApp, meeting transcripts, future channels
-- ============================================
CREATE TABLE wa_intel.messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source_type TEXT NOT NULL DEFAULT 'whatsapp',  -- 'whatsapp' / 'meeting' / future: 'email', 'hmcs_note'
    wa_message_id TEXT UNIQUE,                -- WhatsApp message ID (null for non-WA sources)
    group_id UUID REFERENCES wa_intel.groups(id),
    wa_group_id TEXT,                         -- WhatsApp group JID (null for non-WA sources)
    sender_jid TEXT,                          -- Sender WhatsApp JID (null for non-WA sources)
    sender_name TEXT,                         -- Push name / display name / speaker name
    contact_id UUID REFERENCES wa_intel.contacts(id),
    message_text TEXT,                        -- Isi pesan (teks) atau chunk summary (meeting)
    message_type TEXT DEFAULT 'text',         -- text / image / video / audio / document / sticker / meeting_chunk
    media_url TEXT,                           -- URL media jika ada
    is_from_hendra BOOLEAN DEFAULT false,     -- Flag: apakah pesan/keputusan dari Hendra
    quoted_message_id TEXT,                   -- Jika reply ke pesan lain (WA only)
    meeting_id UUID REFERENCES wa_intel.meetings(id),  -- Link ke meeting record (meeting source only)
    meeting_metadata JSONB,                   -- { chunk_index, total_chunks, start_time, end_time, speakers[] }
    timestamp TIMESTAMPTZ NOT NULL,           -- Waktu pesan dikirim / meeting chunk timestamp
    raw_data JSONB,                           -- Raw message object (Baileys for WA, transcript chunk for meeting)
    created_at TIMESTAMPTZ DEFAULT now()
);

-- Index untuk query umum
CREATE INDEX idx_messages_group_time ON wa_intel.messages(wa_group_id, timestamp DESC);
CREATE INDEX idx_messages_sender ON wa_intel.messages(sender_jid);
CREATE INDEX idx_messages_from_hendra ON wa_intel.messages(is_from_hendra) WHERE is_from_hendra = true;
CREATE INDEX idx_messages_timestamp ON wa_intel.messages(timestamp DESC);
CREATE INDEX idx_messages_source_type ON wa_intel.messages(source_type);
CREATE INDEX idx_messages_meeting_id ON wa_intel.messages(meeting_id) WHERE meeting_id IS NOT NULL;

-- ============================================
-- TABLE 4b: meetings
-- Full meeting records â€” one row per Zoom/offline meeting
-- Chunks are stored in messages table with source_type='meeting'
-- ============================================
CREATE TABLE wa_intel.meetings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    zoom_meeting_id TEXT,                     -- Zoom meeting UUID (null for non-Zoom meetings)
    title TEXT NOT NULL,                      -- Meeting title (e.g., "Rapat Koordinasi Bulanan Feb 2026")
    meeting_date TIMESTAMPTZ NOT NULL,        -- When the meeting took place
    duration_minutes INTEGER,                 -- Total duration
    participants TEXT[],                      -- Array of participant names
    total_chunks INTEGER,                     -- How many 30-min chunks this was split into
    executive_summary TEXT,                   -- AI-generated full meeting summary (synthesized from all chunks)
    raw_transcript TEXT,                      -- Full raw transcript (for search & chat-with-data)
    key_decisions JSONB,                      -- [ { decision, context, owner } ]
    source TEXT DEFAULT 'zoom',               -- 'zoom' / 'google_meet' / 'offline' / 'phone'
    metadata JSONB,                           -- Any additional metadata from Zoom API
    created_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX idx_meetings_date ON wa_intel.meetings(meeting_date DESC);
CREATE INDEX idx_meetings_zoom_id ON wa_intel.meetings(zoom_meeting_id) WHERE zoom_meeting_id IS NOT NULL;

-- ============================================
-- TABLE 5: classified_items
-- Hasil klasifikasi AI dari setiap pesan
-- ============================================
CREATE TABLE wa_intel.classified_items (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    message_id UUID REFERENCES wa_intel.messages(id) ON DELETE CASCADE,
    classification TEXT NOT NULL,             -- 'task' / 'direction' / 'report' / 'question' / 'coordination' / 'noise'
    confidence REAL,                          -- 0.0 - 1.0 confidence score dari AI
    summary TEXT,                             -- Ringkasan 1-2 kalimat dari AI
    assigned_to TEXT,                         -- Nama orang yang di-assign (extracted by AI)
    assigned_by TEXT,                         -- Nama orang yang memberi tugas
    deadline TEXT,                            -- Deadline (extracted by AI, bisa "besok", "minggu depan", dll)
    deadline_parsed TIMESTAMPTZ,             -- Deadline yang sudah di-parse ke timestamp
    topic TEXT,                               -- Topik utama (e.g., "promo ramadan", "shrinkage", "supplier")
    priority TEXT DEFAULT 'normal',           -- 'urgent' / 'high' / 'normal' / 'low'
    ai_model TEXT,                            -- Model yang digunakan (e.g., "gemini-2.0-flash")
    classified_at TIMESTAMPTZ DEFAULT now(),
    created_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX idx_classified_type ON wa_intel.classified_items(classification);
CREATE INDEX idx_classified_time ON wa_intel.classified_items(classified_at DESC);

-- ============================================
-- TABLE 6: tasks
-- Task yang di-extract dari WA, di-track statusnya
-- ============================================
CREATE TABLE wa_intel.tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    classified_item_id UUID REFERENCES wa_intel.classified_items(id),
    source_message_id UUID REFERENCES wa_intel.messages(id),
    title TEXT NOT NULL,                      -- Judul task (dari AI summary)
    description TEXT,                         -- Detail lengkap
    assigned_to TEXT,                         -- Siapa yang harus kerjakan
    assigned_by TEXT,                         -- Siapa yang assign
    group_name TEXT,                          -- Dari grup mana
    status TEXT DEFAULT 'new',                -- 'new' / 'in_progress' / 'done' / 'stuck' / 'cancelled'
    priority TEXT DEFAULT 'normal',           -- 'urgent' / 'high' / 'normal' / 'low'
    deadline TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,
    completion_message_id UUID REFERENCES wa_intel.messages(id),  -- Pesan konfirmasi selesai
    days_without_response INTEGER DEFAULT 0,  -- Berapa hari tanpa response
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX idx_tasks_status ON wa_intel.tasks(status);
CREATE INDEX idx_tasks_assigned ON wa_intel.tasks(assigned_to);

-- ============================================
-- TABLE 7: directions
-- Arahan dari Hendra â€” knowledge base
-- ============================================
CREATE TABLE wa_intel.directions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source_message_id UUID REFERENCES wa_intel.messages(id),
    title TEXT NOT NULL,                      -- Judul arahan (dari AI summary)
    content TEXT NOT NULL,                    -- Isi lengkap arahan
    topic TEXT,                               -- Topik (e.g., "kebijakan retur", "promo ramadan")
    group_name TEXT,                          -- Dari grup mana
    target_audience TEXT,                     -- Untuk siapa (e.g., "semua store manager", "tim purchasing")
    is_still_valid BOOLEAN DEFAULT true,      -- Apakah arahan masih berlaku
    superseded_by UUID REFERENCES wa_intel.directions(id),  -- Jika di-update oleh arahan baru
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX idx_directions_topic ON wa_intel.directions(topic);
CREATE INDEX idx_directions_valid ON wa_intel.directions(is_still_valid) WHERE is_still_valid = true;

-- ============================================
-- TABLE 8: daily_briefings
-- Log daily briefing yang sudah dikirim
-- ============================================
CREATE TABLE wa_intel.daily_briefings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    briefing_date DATE NOT NULL UNIQUE,
    summary_text TEXT NOT NULL,               -- Isi briefing yang dikirim
    new_tasks_count INTEGER DEFAULT 0,
    overdue_tasks_count INTEGER DEFAULT 0,
    completed_tasks_count INTEGER DEFAULT 0,
    new_directions_count INTEGER DEFAULT 0,
    sent_at TIMESTAMPTZ,
    sent_via TEXT DEFAULT 'whatsapp',         -- 'whatsapp' / 'email' / 'telegram'
    created_at TIMESTAMPTZ DEFAULT now()
);

-- ============================================
-- TABLE 9: embeddings (FASE 2 â€” RAG Knowledge Base)
-- Vector embeddings untuk semantic search
-- ============================================
-- CATATAN: Enable pgvector extension dulu di Supabase Dashboard
-- CREATE EXTENSION IF NOT EXISTS vector;

-- CREATE TABLE wa_intel.embeddings (
--     id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
--     source_type TEXT NOT NULL,              -- 'direction' / 'task' / 'message'
--     source_id UUID NOT NULL,                -- ID dari tabel sumber
--     content TEXT NOT NULL,                  -- Teks yang di-embed
--     embedding vector(1536),                 -- OpenAI text-embedding-3-small = 1536 dimensions
--     metadata JSONB,                         -- Extra info: group, sender, topic, date
--     created_at TIMESTAMPTZ DEFAULT now()
-- );
-- CREATE INDEX idx_embeddings_source ON wa_intel.embeddings(source_type, source_id);

-- ============================================
-- VIEWS â€” untuk kemudahan query
-- ============================================

-- View: Tasks yang overdue (belum done, sudah > 3 hari)
CREATE OR REPLACE VIEW wa_intel.overdue_tasks AS
SELECT
    t.*,
    m.message_text AS original_message,
    EXTRACT(DAY FROM now() - t.created_at) AS days_open
FROM wa_intel.tasks t
LEFT JOIN wa_intel.messages m ON m.id = t.source_message_id
WHERE t.status NOT IN ('done', 'cancelled')
AND t.created_at < now() - INTERVAL '3 days';

-- View: Ringkasan per grup hari ini
CREATE OR REPLACE VIEW wa_intel.today_summary AS
SELECT
    g.name AS group_name,
    COUNT(m.id) AS total_messages,
    COUNT(ci.id) FILTER (WHERE ci.classification = 'task') AS task_count,
    COUNT(ci.id) FILTER (WHERE ci.classification = 'direction') AS direction_count,
    COUNT(ci.id) FILTER (WHERE ci.classification = 'report') AS report_count
FROM wa_intel.groups g
LEFT JOIN wa_intel.messages m ON m.wa_group_id = g.wa_group_id
    AND m.timestamp >= CURRENT_DATE
LEFT JOIN wa_intel.classified_items ci ON ci.message_id = m.id
GROUP BY g.name;

-- ============================================
-- RLS (Row Level Security) â€” optional
-- Untuk dashboard authentication nanti
-- ============================================
-- ALTER TABLE wa_intel.messages ENABLE ROW LEVEL SECURITY;
-- ALTER TABLE wa_intel.tasks ENABLE ROW LEVEL SECURITY;
-- (implement RLS policies sesuai kebutuhan)
```

---

## 6) MODULE SPECIFICATIONS

### Module 1: WhatsApp Gateway (Baileys Listener)

**Purpose:** Connect ke WhatsApp via nomor cadangan, listen semua pesan dari semua grup, simpan ke Supabase.

**Tech:** Node.js + @whiskeysockets/baileys v7 + @supabase/supabase-js

**Runs on:** PC kantor, managed by PM2 (long-running process 24/7)

**Input:** WhatsApp WebSocket events (messages.upsert)

**Output:** INSERT ke wa_intel.messages

**Key behaviors:**
- Scan QR code satu kali untuk authenticate
- Persist auth state ke filesystem (auth_info/ folder) â€” supaya tidak perlu scan ulang setiap restart
- Listen event `messages.upsert` â€” setiap pesan baru dari grup manapun
- Parse: sender JID, sender push name, group JID, message text, timestamp, message type
- **Resolve contact:** lookup sender_jid di wa_intel.contacts â†’ get contact_id, role, location. Jika belum ada, auto-create contact entry dengan JID dan push name (jabatan diisi manual nanti).
- Flag `is_from_hendra` berdasarkan JID Hendra (hardcode atau config)
- INSERT ke Supabase `wa_intel.messages` (termasuk contact_id)
- **Saat startup:** fetch metadata semua grup â†’ upsert wa_intel.groups + wa_intel.group_members
- **Listen event `group-participants.update`** â†’ auto-update group_members ketika ada join/leave
- Auto-reconnect jika connection drop (Baileys handle ini, tapi tambah retry logic)
- JANGAN reply atau kirim pesan apapun (read-only) â€” kecuali Module 4 (daily briefing, nanti)
- Log errors ke console + optional log file

**Effort:** ~200-400 LOC, 1-2 hari

**GitHub reference (UTAMA):**
- `jlucaso1/whatsapp-mcp-ts` â€” https://github.com/jlucaso1/whatsapp-mcp-ts
  - Arsitektur Baileys â†’ SQLite â†’ AI query yang paling clean
  - **Cara pakai:** Pelajari cara mereka setup Baileys connection, auth state, dan message handling. Ganti SQLite dengan Supabase client. Buang bagian MCP server â€” kita tidak butuh itu.
- `nizarfadlan/baileys-api` â€” https://github.com/nizarfadlan/baileys-api
  - Baileys sebagai REST API dengan Prisma ORM, webhook, multi-session support
  - **Cara pakai:** Referensi untuk session management, reconnect logic, dan webhook pattern. Jika nanti ingin expose REST API untuk Module 3/4 trigger.
- `farinchan/chatery_whatsapp` â€” https://github.com/farinchan/chatery_whatsapp
  - Express.js + Baileys, paling lengkap: multi-session, WebSocket events, group management, media handling, persistent store
  - **Cara pakai:** Referensi untuk group message handling, media download, dan bulk operations. Arsitekturnya lebih complex â€” ambil bagian yang perlu saja.

**Baileys core library:**
- `WhiskeySockets/Baileys` â€” https://github.com/WhiskeySockets/Baileys
  - Docs: https://baileys.wiki
  - NPM: `npm i @whiskeysockets/baileys`
  - TypeScript, WebSocket-based, no browser/Selenium
  - PENTING: Baileys adalah unofficial library. Gunakan dengan bijak. Jangan spam.

---

### Module 2: Database (Supabase Schema)

**Purpose:** Menyimpan semua data â€” raw messages, classified items, tasks, directions, embeddings.

**Tech:** Supabase PostgreSQL â€” project HMCS existing, schema `wa_intel`

**Key decisions:**
- Schema `wa_intel` terpisah dari schema `public` (HMCS) â€” clarity, tidak saling ganggu
- 9 tabel (lihat Section 5 untuk full SQL)
- pgvector extension untuk Fase 2 RAG
- Views untuk query umum (overdue_tasks, today_summary)
- **Cross-schema query ke HMCS (schema `public`) dimungkinkan** â€” PostgreSQL native support

**Effort:** ~100 LOC (SQL migrations), 3 jam

**Setup steps:**
1. Buka Supabase Dashboard â†’ SQL Editor
2. Jalankan SQL dari Section 5 di atas
3. Verify: semua tabel muncul di schema `wa_intel`
4. (Opsional) Enable pgvector extension untuk Fase 2

---

### Module 3: AI Classifier

**Purpose:** Klasifikasi setiap pesan WA: task / direction / report / question / coordination / noise. Extract entities.

**Tech:** Supabase Edge Function ATAU external Node.js script (cron-based)

**Input:** Pesan baru dari wa_intel.messages (trigger: DB webhook atau cron per 15 menit)

**Output:** INSERT ke wa_intel.classified_items + INSERT ke wa_intel.tasks (jika task) + INSERT ke wa_intel.directions (jika direction dari Hendra)

**AI Prompt Template:**

```
Kamu adalah asisten analisis pesan untuk HollyMart, jaringan supermarket di NTB.

Diberikan pesan WhatsApp dari grup internal perusahaan, klasifikasikan pesan ini.

KONTEKS PENGIRIM:
- Nama: {sender_display_name}
- Jabatan: {sender_role}
- Lokasi: {sender_location}
- Departemen: {sender_department}
- Level leadership: {is_leadership}

KONTEKS GRUP:
- Nama grup: {group_name}
- Deskripsi grup: {group_description}

---
Pengirim: {sender_display_name} ({sender_role}, {sender_location})
Pesan dari Hendra (owner): {is_from_hendra}
Waktu: {timestamp}
Isi pesan:
"{message_text}"
---

Klasifikasikan ke SALAH SATU kategori:
- "task" â€” ada tugas/pekerjaan yang diberikan ke seseorang
- "direction" â€” arahan/kebijakan/memo dari leadership (terutama dari Hendra)
- "report" â€” laporan hasil kerja, update status, angka/data
- "question" â€” pertanyaan yang perlu dijawab
- "coordination" â€” koordinasi rutin (jadwal, konfirmasi kehadiran, dll)
- "noise" â€” chit-chat, sticker, ucapan selamat, tidak ada action item

Jika kategori = "task", extract juga:
- assigned_to: siapa yang harus kerjakan (nama orang)
- assigned_by: siapa yang memberi tugas
- deadline: kapan harus selesai (jika disebutkan)
- priority: "urgent" / "high" / "normal" / "low"

Jika kategori = "direction", extract juga:
- topic: topik utama arahan
- target_audience: untuk siapa arahan ini

Untuk SEMUA kategori:
- summary: ringkasan 1 kalimat dalam Bahasa Indonesia
- confidence: 0.0 - 1.0

PENTING:
- Pesan dari Hendra yang berisi instruksi/kebijakan = "direction"
- Pesan dari Hendra yang menyuruh orang melakukan sesuatu spesifik = "task"
- Jika ragu antara task dan direction, pilih "direction" untuk pesan dari Hendra
- Jika pesan sangat pendek dan ambigu (e.g., "ok", "siap", "ðŸ‘"), klasifikasikan sebagai "noise" atau "coordination"

Respond dalam JSON format SAJA, tanpa markdown:
{
  "classification": "...",
  "summary": "...",
  "confidence": 0.0,
  "assigned_to": "..." atau null,
  "assigned_by": "..." atau null,
  "deadline": "..." atau null,
  "priority": "..." atau null,
  "topic": "..." atau null,
  "target_audience": "..." atau null
}
```

**Processing modes:**
- **Realtime:** Setiap pesan masuk â†’ langsung classify (best UX, tapi lebih mahal API)
- **Batch:** Setiap 15-30 menit, classify semua pesan yang belum di-classify (lebih hemat)
- **Hybrid:** Pesan dari Hendra = realtime. Pesan lain = batch.

**Task completion detection:**
- Jika ada pesan "sudah", "selesai", "done", "sudah dikerjakan" dari orang yang di-assign â†’ flag task sebagai "done"
- Match berdasarkan: same group + same assigned_to + keyword detection + waktu (within 7 hari dari task creation)
- Ini tidak perlu sempurna â€” bisa di-review manual di dashboard

**Effort:** ~300-500 LOC, 2-3 hari + iterasi prompt tuning

---

### Module 4: Daily Briefing + Delivery

**Purpose:** Generate daily summary + kirim ke Hendra setiap pagi jam 7 WIB.
**Status:** âœ… Edge function deployed. ðŸ”œ Delivery mechanism & pg_cron scheduling needed.

**Tech:** Supabase Edge Function (generate) + pg_cron (schedule) + Baileys send (deliver)

**Input:** Query wa_intel.classified_items, wa_intel.tasks, wa_intel.directions dari 24 jam terakhir

**Delivery strategy (FINAL DECISION):**
- **Now:** WhatsApp to self â€” secondary number (listener) sends 1 message/day to Hendra's primary number.
  - Ban risk analysis: 1 message/day to yourself = negligible. WhatsApp has built-in "Message Yourself" feature. This is normal user behavior.
- **Future:** Task notifications to team members will go through **HMCS**, NOT via WhatsApp bot. Reason: HOS Â§7 says "WA is for coordination, not operations." Sending task reminders via WA bot pushes operations back into WA. HMCS is where the team works daily.
- **Fallback:** WhatsApp via secondary number for urgent escalation only (overdue 3+ days, no response).

**Delivery implementation (for Baileys):**
```typescript
// In the listener process (which already has Baileys connected):
// Add a function to send briefing to Hendra's primary number

async function sendDailyBriefing(sock: WASocket, briefingText: string) {
  const hendraJid = process.env.HENDRA_JID; // primary number
  await sock.sendMessage(hendraJid, { text: briefingText });
}

// Triggered by: Supabase webhook when daily_briefings row is inserted
// OR: node-cron in the listener process at 7am WIB
```

**pg_cron schedule (for edge function):**
```sql
-- Generate briefing at 7am WIB (0am UTC, WIB = UTC+8)
SELECT cron.schedule('daily-briefing', '0 23 * * *',
  $$SELECT net.http_post(
    'https://nnzhdjibilebpjgaqkdu.supabase.co/functions/v1/generate-briefing',
    '{}', 'application/json',
    ARRAY[('Authorization', 'Bearer ' || current_setting('app.settings.service_role_key'))]
  )$$
);
```

**Briefing format:**

```
ðŸ“Š HollyMart Daily Brief â€” {tanggal}

ðŸ†• Task Baru (3):
â€¢ [Bima-1] Cek harga kompetitor Indomie â†’ @Andi
â€¢ [Purchasing] Follow up supplier ikan Ramadan â†’ @Hendra
â€¢ [Lombok-2] Atur display promo weekend â†’ @Budi

âš ï¸ Overdue / No Response (1):
â€¢ [Dompu] Kirim laporan shrinkage bulanan â†’ @Dian (5 hari tanpa response)

âœ… Completed (2):
â€¢ [Bima-1] Update harga minyak goreng â†’ @Rina âœ“
â€¢ [Lombok-1] Briefing karyawan baru â†’ @Eko âœ“

ðŸ“ Arahan Baru dari Hendra (1):
â€¢ [All Stores] Kebijakan baru soal retur barang expired

ðŸ’¬ Aktivitas Grup:
â€¢ Bima-1: 45 pesan (8 penting)
â€¢ Purchasing: 23 pesan (5 penting)
â€¢ Dompu: 12 pesan (2 penting)
```

**Effort:** ~200-300 LOC, 1 hari

---

### Module 5: Dashboard (Visual)

**Purpose:** Web dashboard untuk Hendra â€” visual overview, kanban board, search.

**Tech:** Next.js + React + Supabase client + Vercel

**Pages:**

1. **Kanban Board** (/tasks)
   - 4 kolom: New â†’ In Progress â†’ Stuck/Overdue â†’ Done
   - Card: judul task, assigned_to, grup asal, tanggal
   - Drag & drop untuk update status (update wa_intel.tasks)
   - Filter: by group, by assigned_to, by date range

2. **Direction Log** (/directions)
   - List semua arahan dari Hendra, newest first
   - Search by keyword / topic
   - Tag: topic, target_audience, is_still_valid
   - Detail view: isi lengkap + pesan asli dari WA

3. **Group Activity** (/groups)
   - Overview: semua grup, jumlah pesan hari ini, flagged items
   - Click grup â†’ lihat pesan-pesan penting (classified as task/direction/report)
   - Activity chart: message volume per hari per grup

4. **Search** (/search) â€” Fase 2
   - Full-text search across semua messages
   - Semantic search (RAG) for directions dan important messages
   - "Apa kata Hendra soal X?" â†’ AI jawab berdasarkan context

**Effort:** ~800-1200 LOC, 3-5 hari

---

### Module 6: Chat with Data + Knowledge Base

**Purpose:** Search semua data WA + AI Q&A. "Institutional memory." Onboarding tool untuk karyawan baru.
**Status:** ðŸ“‹ Planned â€” Phase A (full-text search) is the priority.

**Implementation approach (pragmatic, layered):**

**Phase A â€” Full-text search (DO THIS FIRST):**

```sql
-- Add search index to messages table
ALTER TABLE wa_intel.messages ADD COLUMN search_vector tsvector
  GENERATED ALWAYS AS (
    to_tsvector('indonesian', COALESCE(body, '') || ' ' || COALESCE(sender_name, ''))
  ) STORED;

CREATE INDEX idx_messages_search ON wa_intel.messages USING GIN(search_vector);

-- Search function
CREATE OR REPLACE FUNCTION wa_intel.search_messages(query text, limit_count int DEFAULT 20)
RETURNS TABLE(id uuid, body text, sender_name text, group_name text, created_at timestamptz, relevance float)
AS $$
  SELECT m.id, m.body, m.sender_name, g.name as group_name, m.created_at,
         ts_rank(m.search_vector, websearch_to_tsquery('indonesian', query)) as relevance
  FROM wa_intel.messages m
  LEFT JOIN wa_intel.groups g ON m.group_id = g.id
  WHERE m.search_vector @@ websearch_to_tsquery('indonesian', query)
  ORDER BY relevance DESC
  LIMIT limit_count;
$$ LANGUAGE sql;
```

**Phase B â€” AI-powered Q&A edge function:**

```typescript
// New edge function: chat-with-data
// 1. Take user's natural language question
// 2. Search messages + tasks + directions using full-text search
// 3. Send matching results as context to GPT-4o-mini
// 4. AI answers based ONLY on the data, not general knowledge

const systemPrompt = `You are HollyMart's WhatsApp Intelligence assistant.
Answer questions ONLY based on the WhatsApp data provided below.
If the data doesn't contain the answer, say "Data tidak ditemukan di chat WA."
Always mention the source group and date.
Respond in Bahasa Indonesia.`;

const context = searchResults.map(m =>
  `[${m.group_name}] ${m.sender_name} (${m.created_at}): ${m.body}`
).join('\n');

// Send to AI with retrieved context
const response = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [
    { role: 'system', content: systemPrompt },
    { role: 'user', content: `Data WhatsApp:\n${context}\n\nPertanyaan: ${userQuestion}` }
  ]
});
```

**Phase C â€” Dashboard chat page:**
Add a chat interface to the React dashboard â€” text input + AI response. This is the "Chat with WA Data" page.

**Phase D â€” Knowledge base features:**
- Topic tagging for directions (AI adds topics[] during classification)
- Directions search page with filters (by topic, date, store)
- "Onboarding Pack" generator: select a store/role â†’ compile relevant directions from last 6 months â†’ AI generates summary â†’ export as PDF

**Phase E (only if full-text search insufficient) â€” Vector/semantic search:**
- Supabase pgvector + OpenAI text-embedding-3-small
- Embeddings cost: ~$0.50-1/bulan (very cheap)
- Reference: `supabase-community/chatgpt-your-files` on GitHub

**Effort:** Phase A: 1 day, Phase B: 1 day, Phase C: 1-2 days, Phase D: 3-5 days, Phase E: 2-3 days

---

### Module 7: Meeting Transcript Ingestion (Zoom via n8n)

**Purpose:** Automatically capture, chunk, summarize, and ingest meeting transcripts into the HMSO pipeline.
**Status:** ðŸ“‹ Planned â€” next module to build after WhatsApp pipeline is stable.

**Why this matters:**
Rapat Koordinasi Bulanan can run 1-8 hours. Decisions made, tasks assigned, policies announced â€” all trapped in people's memory or scattered notes. HOS v1 Â§6: "If it's not written, it didn't happen." Meeting transcripts are the highest-density signal source in the organization.

**Tech:** n8n (self-hosted on same VPS) + Zoom API webhook + OpenRouter (premium AI model)

**End-to-end flow:**

```
Zoom meeting ends
    â”‚
    â–¼ (Zoom webhook â†’ n8n)
n8n Workflow:
    â”‚
    â”œâ”€â”€ Step 1: Receive Zoom webhook payload
    â”‚   Contains: meeting_id, topic, start_time, duration, transcript_url
    â”‚
    â”œâ”€â”€ Step 2: Fetch full transcript from Zoom API
    â”‚   GET /meetings/{meetingId}/recordings â†’ download transcript (.vtt or .txt)
    â”‚
    â”œâ”€â”€ Step 3: INSERT meeting record into wa_intel.meetings
    â”‚   { title, date, duration, participants, raw_transcript, source='zoom' }
    â”‚   Returns: meeting_id (UUID)
    â”‚
    â”œâ”€â”€ Step 4: Chunk transcript into 30-min segments
    â”‚   - Split by timestamp, not character count
    â”‚   - ~2 min overlap between chunks (context continuity)
    â”‚   - If meeting < 30 min â†’ single chunk
    â”‚   - 1hr meeting = 2 chunks, 3hr = 6 chunks, 8hr = 16 chunks
    â”‚
    â”œâ”€â”€ Step 5: For EACH chunk â†’ AI summarization via OpenRouter
    â”‚   Model: Claude Sonnet or GPT-4o (premium, not mini)
    â”‚   System prompt:
    â”‚   """
    â”‚   You are a meeting intelligence assistant for HollyMart, a supermarket
    â”‚   chain in NTB, Indonesia. Analyze this meeting transcript segment.
    â”‚
    â”‚   Extract and return in Bahasa Indonesia:
    â”‚   1. RINGKASAN: 3-5 bullet point summary of this segment
    â”‚   2. KEPUTUSAN: Decisions made (who decided, what was decided)
    â”‚   3. TASK: Tasks assigned (assignee, description, deadline if mentioned)
    â”‚   4. ARAHAN: Directives or policy announcements (especially from Hendra/leadership)
    â”‚   5. ESKALASI: Issues that need follow-up or were left unresolved
    â”‚   6. PESERTA AKTIF: Who spoke most / contributed to decisions
    â”‚
    â”‚   If Hendra Rusly is speaking and giving instructions, always classify
    â”‚   those as ARAHAN regardless of tone (formal or casual).
    â”‚
    â”‚   Return as structured JSON.
    â”‚   """
    â”‚
    â”œâ”€â”€ Step 6: INSERT each chunk summary into wa_intel.messages
    â”‚   {
    â”‚     source_type: 'meeting',
    â”‚     message_text: chunk_summary_text,
    â”‚     message_type: 'meeting_chunk',
    â”‚     meeting_id: <from step 3>,
    â”‚     meeting_metadata: {
    â”‚       chunk_index: 1,
    â”‚       total_chunks: 6,
    â”‚       start_time: "00:00:00",
    â”‚       end_time: "00:30:00",
    â”‚       speakers: ["Hendra", "Andi", "Budi"]
    â”‚     },
    â”‚     is_from_hendra: <true if Hendra spoke in this chunk>,
    â”‚     timestamp: <meeting_date + chunk start offset>,
    â”‚     raw_data: { chunk_raw_transcript, ai_response_json }
    â”‚   }
    â”‚
    â”œâ”€â”€ Step 7: After ALL chunks processed â†’ generate executive summary
    â”‚   Send all chunk summaries to AI â†’ synthesize into 1-page executive summary
    â”‚   UPDATE wa_intel.meetings SET executive_summary = <result>
    â”‚
    â””â”€â”€ Step 8: Existing pipeline takes over automatically
          - Classifier picks up meeting chunks (same 15-min cron)
          - Tasks/directions extracted and populated
          - Next daily briefing includes meeting highlights
          - Chat-with-data can search meeting content
          - HMCS receives meeting-sourced tasks
```

**Chunk overlap strategy:**
```
Meeting timeline: |====================================|
                  0m      30m      60m      90m

Chunk 1: |==========...==|
          0m           32m (30 min + 2 min overlap)

Chunk 2:           |==..==========...==|
                   28m              62m (starts 2 min before boundary)

Chunk 3:                      |==..==========...==|
                              58m              92m
```
The 2-minute overlap ensures that if someone says "as I was saying about the supplier issue" at minute 30, the next chunk has the context of what they were saying.

**n8n on VPS setup:**
```bash
# n8n runs on same Biznet NEO Lite VPS as Baileys listener
# Install via Docker (recommended) or npm

# Docker approach:
docker run -d --name n8n \
  -p 5678:5678 \
  -v n8n_data:/home/node/.n8n \
  -e N8N_BASIC_AUTH_ACTIVE=true \
  -e N8N_BASIC_AUTH_USER=admin \
  -e N8N_BASIC_AUTH_PASSWORD=<secure_password> \
  n8nio/n8n

# Or via npm + PM2 (alongside Baileys):
npm install -g n8n
pm2 start n8n --name "n8n"
```

**Required Zoom configuration:**
1. Create Zoom App (Server-to-Server OAuth) at marketplace.zoom.us
2. Enable "Meeting" event subscription â†’ "Meeting ended" webhook
3. Enable Cloud Recording with auto-transcription
4. Webhook URL: `https://<your-vps-ip>:5678/webhook/zoom-meeting-ended`

**Handling meetings WITHOUT Zoom (offline rapatx):**
For offline meetings or phone calls, manual upload path:
- Upload audio file to a simple web form on dashboard
- n8n workflow: receive file â†’ Whisper API (speech-to-text) â†’ same pipeline as Zoom
- Or: paste meeting notes manually into a form â†’ insert as single chunk

**Classifier awareness (update classifier prompt):**
The existing AI classifier must understand meeting chunks differently from WhatsApp messages:
```
When source_type='meeting': This is a 30-minute segment summary from a meeting transcript.
It may contain MULTIPLE tasks, directions, and decisions within a single message.
Extract ALL of them, not just the primary one.
Weight decisions and directions higher â€” meetings are where policy is made.
```

**Estimated cost per meeting:**
| Meeting Length | Chunks | AI Calls | Est. Cost |
|---|---|---|---|
| 1 hour | 2 | 3 (2 chunks + 1 exec summary) | ~$0.15-0.30 |
| 3 hours | 6 | 7 | ~$0.45-0.90 |
| 8 hours | 16 | 17 | ~$1.20-2.40 |

At 4-8 meetings per month: **~$2-10/month total.**

**Effort:** n8n workflow: 1-2 days. Prompt engineering: 1 day. Testing with real transcripts: 1-2 days. **Total: ~3-5 days.**

---

### Module 8: HMCS Integration

(See Section 14 for full architecture. Summary here for reference.)

**Purpose:** Route HMSO outputs (tasks, briefings, directions) into HMCS where the team already works daily.
**Status:** ðŸ“‹ Planned â€” after WhatsApp pipeline stable + meeting ingestion working.

**Implementation:** Start with Pattern A (HMCS reads wa_intel tables directly). Move to Pattern B (API push) when HMCS needs tasks in its own schema.

**Key rule:** Team never needs to know HMSO exists. They just see tasks and briefings appear in HMCS.

---

## 7) BUILD ORDER (Phased Approach)

### Fase 1: Listen & Store âœ… DONE
**Status:** Completed Feb 9, 2026.
- Supabase schema `wa_intel` created (8 tables, 2 views)
- Baileys listener running 24/7 on VPS
- 18,500+ messages captured, 299 groups synced, 11,900+ contacts

### Fase 2: Classify & Brief âœ… PARTIALLY DONE
**Status:** Edge functions deployed. Needs activation & iteration.
- âœ… AI classifier edge function deployed (GPT-4o-mini)
- âœ… Daily briefing edge function deployed
- ðŸ”œ Activate pg_cron scheduling (classify every 15 min, briefing daily 7am)
- ðŸ”œ Fix classification label mismatch in dashboard
- ðŸ”œ Fix messages-to-groups foreign key linking
- ðŸ”œ Batch classify all 18k+ accumulated messages
- ðŸ”œ Iterate classification prompt quality (assignee detection, deadline extraction)

### Fase 3: Dashboard âœ… PARTIALLY DONE
**Status:** React app built via Bolt.new with Supabase Auth.
- âœ… Pages: Overview, Tasks (kanban), Directions, Contacts, Groups, Briefings
- ðŸ”œ Enforce auth on all pages
- ðŸ”œ Fix data display issues

### Fase 4: Delivery (NEXT)
**Goal:** Hendra gets daily brief on WhatsApp without opening the dashboard.
1. Add sending capability to Baileys listener (secondary â†’ primary number)
2. Trigger: after briefing edge function generates â†’ listener sends to Hendra's WA
3. Add overdue task alerts (conditional â€” only send when items are overdue)

**Deliverable:** Every morning, 1 WhatsApp message with daily intel. Overdue alerts when needed.

### Fase 5: Chat with Data
**Goal:** Ask questions, get AI answers from your WA data.
1. Add full-text search to messages table (tsvector)
2. Build chat-with-data edge function
3. Add chat page to dashboard
4. Topic tagging for directions

**Deliverable:** "Apa yang dibicarakan grup Bima kemarin?" â†’ AI answers from actual data.

### Fase 6: Meeting Transcript Ingestion
**Goal:** Zoom meetings auto-captured, chunked, summarized, and fed into the pipeline.
1. Install n8n on VPS (Docker or PM2)
2. Configure Zoom Server-to-Server OAuth + webhook
3. Build n8n workflow: receive webhook â†’ fetch transcript â†’ chunk â†’ AI summarize â†’ insert
4. Run database migration (add source_type, meeting_metadata to messages + create meetings table)
5. Update classifier prompt to handle meeting chunks (multiple tasks per chunk)
6. Test with real Rapat Koordinasi transcript
7. Build executive summary generation (synthesize all chunks)
8. Optional: manual upload path for offline meetings

**Deliverable:** Meeting ends â†’ transcript automatically chunked, summarized, tasks extracted. Next morning briefing includes meeting highlights. Searchable forever.

### Fase 7: Knowledge Base & Onboarding
**Goal:** Searchable directions, onboarding pack for new staff.
1. Directions search page with filters (topic, date, store)
2. Onboarding pack generator (compile directions â†’ AI summary â†’ PDF)
3. (Optional) Vector search with pgvector if full-text search insufficient

**Deliverable:** New store manager joins â†’ generate onboarding brief from 6 months of directions.

### Fase 8: HMCS Integration (FUTURE)
**Goal:** HMSO feeds structured data into HMCS where the team already works.
1. Check HMCS API capabilities (create tasks? push notifications?)
2. Start with Pattern A: HMCS reads directly from wa_intel schema
3. If needed, Pattern B: edge function pushes to HMCS API
4. Tasks appear in HMCS task system, briefings as dashboard widget

**Deliverable:** Team sees WA-extracted tasks in HMCS. They don't need to know HMSO exists.

---

## 8) CROSS-SCHEMA QUERIES (wa_intel â†” HMCS)

Schema `wa_intel` dan schema `public` (HMCS) berada di **database PostgreSQL yang sama**. PostgreSQL native support cross-schema query â€” tidak perlu API call, tidak perlu join antar database. Ini keuntungan utama pakai project Supabase yang sama.

### Contoh Query Cross-Schema

```sql
-- Contoh 1: Enrichment â€” gabungkan data WA dengan data karyawan HMCS
SELECT
    m.message_text,
    c.display_name,
    c.role,
    e.employee_id,        -- dari tabel HMCS
    e.hire_date            -- dari tabel HMCS
FROM wa_intel.messages m
JOIN wa_intel.contacts c ON c.id = m.contact_id
LEFT JOIN public.employees e ON e.phone_number = c.phone_number;

-- Contoh 2: Cari task dari store manager yang baru direkrut < 3 bulan
SELECT t.*
FROM wa_intel.tasks t
JOIN wa_intel.contacts c ON c.short_name = t.assigned_to
LEFT JOIN public.employees e ON e.phone_number = c.phone_number
WHERE c.role = 'Store Manager'
AND e.hire_date > now() - INTERVAL '3 months';

-- Contoh 3: Nanti jika HMCS punya tabel stores, bisa join lokasi
SELECT
    g.name AS group_name,
    s.store_code,          -- dari HMCS
    s.city,                -- dari HMCS
    COUNT(m.id) AS message_count
FROM wa_intel.groups g
LEFT JOIN public.stores s ON g.name ILIKE '%' || s.store_name || '%'
LEFT JOIN wa_intel.messages m ON m.wa_group_id = g.wa_group_id
GROUP BY g.name, s.store_code, s.city;
```

### Catatan Penting Cross-Schema
- `wa_intel` schema menggunakan `SUPABASE_SERVICE_ROLE_KEY` di server (Baileys listener) â€” ini bypass RLS dan bisa access semua schema.
- Dashboard (client-side) menggunakan `SUPABASE_ANON_KEY` â€” perlu set RLS policy yang tepat untuk tabel wa_intel yang diakses.
- Field `hmcs_employee_id` di tabel `wa_intel.contacts` adalah bridge opsional ke data HMCS â€” populate ini secara manual atau via script matching nomor HP.
- JANGAN buat foreign key constraint cross-schema (wa_intel â†’ public) karena bisa menyulitkan migrasi nanti. Gunakan soft reference (matching by phone_number atau employee_id).

---

## 9) CONTACTS MANAGEMENT

### Kenapa Tabel Contacts Penting?

Tanpa tabel `contacts`, AI classifier hanya tahu "628123456789 mengirim pesan di grup." Dengan contacts, AI tahu "Budi Santoso (Store Manager, Bima-1) mengirim pesan di grup Operasional Bima." Ini meningkatkan akurasi klasifikasi secara drastis.

### Cara Populate Contacts

**Opsi A: Manual (recommended untuk awal)**
- Hendra atau admin HO input data via Supabase Dashboard atau simple admin page
- Data yang dibutuhkan per orang: nomor WA, nama, jabatan, lokasi, departemen
- Estimasi: 50-100 orang = 30 menit kerja manual

**Opsi B: Auto-discover dari Baileys (enrichment)**
- Baileys bisa detect participants di setiap grup
- Saat pertama kali listen, auto-create contact entry dengan JID dan push name
- Data jabatan/lokasi tetap perlu diisi manual (atau dari HMCS)

**Opsi C: Import dari HMCS (jika data karyawan sudah ada)**
```sql
-- Jika HMCS sudah punya tabel employees dengan nomor HP:
INSERT INTO wa_intel.contacts (wa_jid, phone_number, display_name, role, location, hmcs_employee_id)
SELECT
    e.phone_number || '@s.whatsapp.net',
    e.phone_number,
    e.full_name,
    e.position,
    e.store_location,
    e.id
FROM public.employees e
WHERE e.phone_number IS NOT NULL
ON CONFLICT (wa_jid) DO UPDATE SET
    display_name = EXCLUDED.display_name,
    role = EXCLUDED.role,
    location = EXCLUDED.location,
    hmcs_employee_id = EXCLUDED.hmcs_employee_id;
```

### Auto-Sync Group Members dari Baileys

Module 1 (Baileys listener) bisa otomatis populate `group_members` tabel:
- Saat startup: fetch group metadata untuk semua grup â†’ insert/update group_members
- Listen event `group-participants.update` â†’ auto-update ketika ada orang join/leave grup
- Ini memberi visibility: siapa saja di grup mana, kapan join, apakah admin

---

## 10) RISKS & MITIGATIONS

| Risk | Likelihood | Impact | Mitigation |
|---|---|---|---|
| WhatsApp ban (listener â€” read only) | Very Low | Medium | Read-only behavior. Nomor cadangan, bukan operasional. |
| WhatsApp ban (sending briefing â€” 1 msg/day to self) | Negligible | Low | 1 pesan/hari ke diri sendiri. WA punya fitur "Message Yourself". Normal behavior. |
| WhatsApp ban (future â€” sending task reminders to team) | Low-Medium | Medium | Low volume (5-20/day), to known contacts, natural language. Mitigate: route through HMCS instead of WA bot. |
| Baileys breaking change (WA update protocol) | Low-Medium | High | Baileys actively maintained, community besar. Monitor GitHub issues. |
| AI classification inaccurate | High (awalnya) | Low | Iterasi prompt. Human review di dashboard. Feedback loop. 80% akurasi sudah membantu. |
| VPS downtime / restart | Low | Medium | PM2 auto-restart. Auth state persisted. Missed messages saat offline = acceptable loss. |
| Supabase free tier limit | Low | Low | 500MB storage cukup. Monitor usage. Upgrade jika perlu ($25/mo). |
| HMCS API changes break integration | Low | Medium | Soft reference (no foreign keys cross-schema). Pattern A (direct read) is resilient. |

### Ban Risk Deep Analysis (WhatsApp Sending)

**Apa yang membuat WhatsApp ban akun:**
- Mengirim pesan massal ke nomor yang tidak dikenal
- Spam ke banyak grup dalam waktu singkat
- Automated behavior yang terlihat seperti marketing bot
- Volume tinggi (ratusan pesan per jam)

**Apa yang TIDAK akan trigger ban:**
- 1 pesan/hari ke nomor sendiri (fitur "Message Yourself" ada di WA resmi)
- 5-20 pesan/hari ke kontak yang sudah disimpan dan saling kenal
- Pesan dengan bahasa natural (bukan template robotik)
- Pesan yang berisi konten relevan (bukan iklan/spam)

**Keputusan:**
- Daily briefing to self: âœ… AMAN â€” lakukan sekarang
- Task reminders to team (future): âœ… AMAN jika low volume + natural language, tapi LEBIH BAIK via HMCS
- Bulk notifications to all stores: âŒ JANGAN â€” gunakan HMCS

---

## 11) HENDRA'S IDENTIFIER

Untuk Module 1 (flag `is_from_hendra`) dan Module 3 (special handling direction), konfigurasi JID Hendra:

```
HENDRA_JID=628xxxxxxxxxx@s.whatsapp.net
```

Ganti `628xxxxxxxxxx` dengan nomor WhatsApp Hendra. Ini digunakan untuk:
- Flag pesan dari Hendra di database
- AI classifier: pesan dari Hendra yang berisi instruksi â†’ otomatis classify sebagai "direction"
- Daily briefing: section khusus "Arahan Baru dari Hendra"

---

## 12) FILE STRUCTURE (Suggested)

```
hmso/
â”œâ”€â”€ README.md
â”œâ”€â”€ HMSO_BLUEPRINT.md               â† FILE INI (context document / North Star)
â”œâ”€â”€ package.json
â”œâ”€â”€ .env                            â† All API keys, Supabase, Zoom, OpenRouter
â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ listener/                       â† Module 1: Baileys WhatsApp Listener
â”‚   â”œâ”€â”€ index.ts                    â† Main entry point â€” Baileys setup, message handler
â”‚   â”œâ”€â”€ supabase.ts                 â† Supabase client config
â”‚   â”œâ”€â”€ message-handler.ts          â† Parse & save messages (source_type='whatsapp')
â”‚   â”œâ”€â”€ send-briefing.ts            â† Send daily brief to Hendra's WA (1x/day)
â”‚   â””â”€â”€ auth_info/                  â† Baileys auth state (gitignore this)
â”‚
â”œâ”€â”€ classifier/                     â† Module 3: AI Classifier (all sources)
â”‚   â”œâ”€â”€ classify.ts                 â† Main classifier logic
â”‚   â”œâ”€â”€ prompt.ts                   â† AI prompt templates (WA vs meeting variants)
â”‚   â”œâ”€â”€ task-detector.ts            â† Detect task completion from replies
â”‚   â””â”€â”€ batch-process.ts            â† Batch classify unprocessed messages
â”‚
â”œâ”€â”€ briefing/                       â† Module 4: Daily Briefing
â”‚   â”œâ”€â”€ generate-briefing.ts        â† Query data from ALL sources, format summary
â”‚   â”œâ”€â”€ send-briefing.ts            â† Trigger Baileys to send via WA
â”‚   â””â”€â”€ cron.ts                     â† Cron job setup (or managed by pg_cron)
â”‚
â”œâ”€â”€ meetings/                       â† Module 7: Meeting Transcript Ingestion
â”‚   â”œâ”€â”€ chunk-transcript.ts         â† Split transcript into 30-min segments
â”‚   â”œâ”€â”€ summarize-chunk.ts          â† AI summarization via OpenRouter
â”‚   â”œâ”€â”€ executive-summary.ts        â† Synthesize all chunks into 1-page summary
â”‚   â”œâ”€â”€ ingest-meeting.ts           â† Full pipeline: fetch â†’ chunk â†’ summarize â†’ insert
â”‚   â””â”€â”€ manual-upload.ts            â† Manual upload path for offline meetings
â”‚
â”œâ”€â”€ chat/                           â† Module 6: Chat with Data
â”‚   â”œâ”€â”€ search.ts                   â† Full-text search across all messages + meetings
â”‚   â”œâ”€â”€ chat-with-data.ts           â† AI Q&A edge function
â”‚   â””â”€â”€ knowledge-base.ts           â† Direction search, onboarding pack generator
â”‚
â”œâ”€â”€ dashboard/                      â† Module 5: React Dashboard
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx                â† Home / overview
â”‚   â”‚   â”œâ”€â”€ tasks/page.tsx          â† Kanban board
â”‚   â”‚   â”œâ”€â”€ directions/page.tsx     â† Direction log
â”‚   â”‚   â”œâ”€â”€ meetings/page.tsx       â† Meeting transcripts & summaries
â”‚   â”‚   â”œâ”€â”€ groups/page.tsx         â† Group activity
â”‚   â”‚   â”œâ”€â”€ chat/page.tsx           â† Chat with Data (AI Q&A)
â”‚   â”‚   â””â”€â”€ search/page.tsx         â† Full-text search
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ supabase.ts
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ n8n/                            â† n8n workflow exports (for version control)
â”‚   â””â”€â”€ zoom-meeting-ingestion.json â† Exportable n8n workflow definition
â”‚
â”œâ”€â”€ supabase/
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 001_create_wa_intel_schema.sql
â”‚       â”œâ”€â”€ 002_add_source_type_and_meetings.sql  â† New: multi-source support
â”‚       â””â”€â”€ 003_add_full_text_search.sql           â† New: tsvector indexes
â”‚
â””â”€â”€ ecosystem.config.js             â† PM2 config for Baileys listener + n8n
```

---

## 13) ENVIRONMENT VARIABLES

### Supabase Connection (HMCS Project â€” EXISTING)

**PENTING: Project ini menggunakan database Supabase HMCS yang SUDAH ADA. JANGAN buat project Supabase baru.**

```
Supabase Project URL: https://nnzhdjibilebpjgaqkdu.supabase.co
Supabase Project ID:  nnzhdjibilebpjgaqkdu
```

Semua tabel hmso harus dibuat di schema `wa_intel` â€” BUKAN di schema `public`.
Schema `public` sudah digunakan oleh HMCS. Jangan sentuh, jangan modify, jangan drop apapun di schema `public`.

### Environment Variables (.env)

```env
# Supabase (HMCS project â€” EXISTING, JANGAN BUAT BARU)
SUPABASE_URL=https://nnzhdjibilebpjgaqkdu.supabase.co
SUPABASE_ANON_KEY=<get from Supabase Dashboard â†’ Settings â†’ API>
SUPABASE_SERVICE_ROLE_KEY=<get from Supabase Dashboard â†’ Settings â†’ API>

# PENTING: Untuk frontend (Bolt/Vite), gunakan prefix VITE_
VITE_SUPABASE_URL=https://nnzhdjibilebpjgaqkdu.supabase.co
VITE_SUPABASE_ANON_KEY=<same anon key>

# Hendra identifier
HENDRA_JID=628xxxxxxxxxx@s.whatsapp.net

# AI API (pick one â€” keys disimpan di .env, JANGAN di source code)
OPENAI_API_KEY=<get from platform.openai.com/api-keys>
# GEMINI_API_KEY=<alternative: get from aistudio.google.com>
# ANTHROPIC_API_KEY=<alternative: get from console.anthropic.com>

# Daily briefing delivery
BRIEFING_RECIPIENT_JID=628xxxxxxxxxx@s.whatsapp.net
BRIEFING_TIME=07:00

# Meeting Transcript Ingestion (Zoom + OpenRouter)
ZOOM_ACCOUNT_ID=<from marketplace.zoom.us â†’ Server-to-Server app>
ZOOM_CLIENT_ID=<from marketplace.zoom.us>
ZOOM_CLIENT_SECRET=<from marketplace.zoom.us>
ZOOM_WEBHOOK_SECRET=<webhook verification token>

# OpenRouter (for premium AI â€” meeting summaries)
OPENROUTER_API_KEY=<from openrouter.ai/keys>
OPENROUTER_MODEL=anthropic/claude-sonnet-4-20250514  # or openai/gpt-4o

# n8n (if self-hosted)
N8N_PORT=5678
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=<secure_password>
```

### SECURITY RULES
- **JANGAN PERNAH** commit `.env` file ke Git
- **JANGAN PERNAH** taruh API keys di source code, markdown, atau chat
- Tambahkan `.env` ke `.gitignore`
- Untuk Bolt: masukkan keys via Bolt's environment/secrets panel, bukan di code

---

## 13b) INSTRUKSI KHUSUS UNTUK BOLT.NEW

Jika project ini dikerjakan menggunakan Bolt.new:

1. **Database:** Gunakan Supabase project EXISTING (URL: `https://nnzhdjibilebpjgaqkdu.supabase.co`). JANGAN buat project Supabase baru. JANGAN jalankan `npx supabase init` atau setup Supabase baru.

2. **Schema:** Semua SQL migrations harus target schema `wa_intel`. Setiap CREATE TABLE harus diawali `wa_intel.` â€” contoh: `CREATE TABLE wa_intel.messages (...)`. JANGAN gunakan schema `public`.

3. **Existing tables di `public`:** Ada tabel-tabel HMCS di schema `public`. JANGAN query, modify, atau drop tabel-tabel ini. Mereka bukan bagian dari project hmso.

4. **Environment variables:** Set di Bolt's environment panel:
   - `VITE_SUPABASE_URL`
   - `VITE_SUPABASE_ANON_KEY`
   - `OPENAI_API_KEY` (atau AI provider lain)

5. **Supabase client config:** Pastikan client mengarah ke project existing:
   ```typescript
   import { createClient } from '@supabase/supabase-js'
   const supabase = createClient(
     import.meta.env.VITE_SUPABASE_URL,
     import.meta.env.VITE_SUPABASE_ANON_KEY
   )
   ```

6. **Querying wa_intel schema dari Supabase JS client:** 
   Supabase JS client default ke schema `public`. Untuk query schema `wa_intel`, ada 2 cara:
   
   **Cara 1 (recommended):** Buat client kedua khusus wa_intel:
   ```typescript
   const waIntel = createClient(
     import.meta.env.VITE_SUPABASE_URL,
     import.meta.env.VITE_SUPABASE_ANON_KEY,
     { db: { schema: 'wa_intel' } }
   )
   // Lalu query normal:
   const { data } = await waIntel.from('messages').select('*')
   // Ini otomatis query wa_intel.messages
   ```
   
   **Cara 2:** Gunakan RPC (SQL function) untuk query complex cross-schema.

7. **Baileys listener:** Bolt.new TIDAK bisa menjalankan Baileys listener (butuh long-running Node.js process). Bolt hanya untuk Dashboard (Module 5). Baileys listener (Module 1) harus di-run terpisah di PC/server.

8. **Fokus Bolt:** Gunakan Bolt untuk build:
   - Dashboard (Module 5): Next.js/Vite + React, kanban board, direction log, group activity
   - Bisa juga: Admin page untuk manage contacts (wa_intel.contacts)
   - Bisa juga: Search interface (Module 6 â€” Fase 2)

---

## 14) HMCS INTEGRATION ARCHITECTURE (Ready When You Are)

### Context
HMCS (HollyMart Central System) is the primary operational system used daily by the HollyMart team. It has an API. It lives in the same Supabase database as HMSO (schema `public`). HMSO's role is to be the invisible intelligence feeder â€” data flows one way: HMSO â†’ HMCS.

### What HMSO Produces (outputs HMCS can consume)

| Output | Table/View | Description |
|---|---|---|
| Classified messages | `wa_intel.classified_items` | Every message tagged: task, direction, report, question, coordination, noise |
| Extracted tasks | `wa_intel.tasks` | AI-detected action items with description, source group, assignee, deadline |
| Extracted directions | `wa_intel.directions` | Leadership memos and directives with context |
| Daily briefings | `wa_intel.daily_briefings` | Pre-generated summary in Bahasa Indonesia |
| Contacts | `wa_intel.contacts` | Auto-discovered people with phone numbers |
| Overdue tasks | `wa_intel.overdue_tasks` (view) | Tasks past deadline or stale |

### Integration Patterns (pick based on HMCS capabilities)

**Pattern A â€” Same Database, Direct Read (START HERE)**

Since both schemas live in the same Supabase instance, HMCS can simply query `wa_intel.*` tables directly. No API needed. Zero effort.

```sql
-- HMCS can read HMSO data directly:
SELECT * FROM wa_intel.tasks WHERE status = 'new' ORDER BY created_at DESC;
SELECT * FROM wa_intel.daily_briefings WHERE DATE(created_at) = CURRENT_DATE;
SELECT * FROM wa_intel.overdue_tasks;
```

Use cases:
- HMCS dashboard widget showing "HMSOligence Summary"
- HMCS task list incorporating WA-extracted tasks
- HMCS notification system reading from wa_intel.overdue_tasks

**Pattern B â€” API Push (LATER, if HMCS needs tasks in its own schema)**

A Supabase Edge Function watches for new classified items and pushes them to HMCS via its API.

```
New task in wa_intel.tasks
  â†’ database trigger fires
  â†’ calls edge function "sync-to-hmcs"
  â†’ POST to HMCS API: /api/tasks/create
  â†’ HMCS handles notification to assigned user
```

When to use: If HMCS has its own task management system with assignment, status tracking, and notifications that require tasks to live in HMCS's own tables.

**Pattern C â€” Hybrid (RECOMMENDED LONG-TERM)**

- HMCS reads briefings and directions directly from wa_intel schema (Pattern A)
- Tasks get pushed via API (Pattern B) into HMCS's task system
- Overdue alerts triggered by HMCS's own notification mechanism

### Key Design Rules

1. **One-way flow.** HMSO â†’ HMCS. Never reverse. WA data feeds into operations, not the other way.
2. **No foreign keys cross-schema.** Use soft references (matching by phone_number or employee_id). Keeps schemas independently migratable.
3. **HMSO stays invisible.** Tim tidak perlu tahu HMSO ada. Mereka hanya melihat task dan briefing muncul di HMCS.
4. **Delivery goes through HMCS.** Task notifications to team members should come from HMCS (the system they already use), not from a WhatsApp bot. HOS Â§7: "WA is for coordination, not operations."
5. **WhatsApp sending reserved for:** Hendra's personal daily brief (1 msg/day) and future urgent escalation only.

### Implementation Checklist (when ready)

- [ ] Check HMCS API: can it create tasks? (POST /api/tasks or equivalent)
- [ ] Check HMCS API: can it push notifications to users?
- [ ] If yes to both â†’ implement Pattern B edge function (sync-to-hmcs)
- [ ] If no â†’ use Pattern A (HMCS reads from wa_intel tables directly)
- [ ] Add HMCS dashboard widget for HMSOligence summary
- [ ] Map wa_intel.contacts to HMCS employees (phone number matching)
- [ ] Test: task created in WA â†’ appears in HMCS â†’ assigned user sees notification

---

## 15) OPENCLAW CONTEXT (Why We Didn't Use It)

### What is OpenClaw?
OpenClaw (formerly Clawdbot, Moltbot) is an open-source self-hosted AI personal assistant created by Peter Steinberger. 68,000+ GitHub stars. It connects messaging apps (WhatsApp, Telegram, Discord) to an AI agent that can execute tasks on your computer (shell commands, file operations, browser control). Uses Baileys for WhatsApp integration (same library as HMSO).

### Why Rejected for HollyMart

| Reason | Detail |
|---|---|
| Security risk | AI has full shell access to host machine. Cybersecurity researchers have raised concerns. |
| Single-user design | Personal assistant, not team tool. No multi-user, no dashboard, no analytics. |
| No classification | Doesn't categorize messages. Just processes what you send it. |
| No visual dashboard | Conversation-only interface. No kanban, no overview, no search page. |
| Overkill | Can control computer, send emails, manage calendar. We just need: read WA â†’ classify â†’ brief. |
| Sends messages via WA | Increases ban risk. HMSO listener is read-only by design. |
| HOS v1 violation | Black box decision making violates "Clarity > Speed". |

### What OpenClaw Users Build (that we should steal ideas from)

Based on research of OpenClaw community (Feb 2026), these are the patterns relevant to HMSO:

1. **Morning briefing via cron** â†’ We have this (Module 4). Add WhatsApp delivery.
2. **Chat with your data (conversational AI)** â†’ Build this (Module 6 Phase B). Edge function + full-text search.
3. **Auto-create tasks from messages** â†’ We have this (Module 3 classifier). Improve prompt quality.
4. **Proactive overdue alerts** â†’ Build this. Edge function + conditional notification.
5. **Knowledge base / second brain** â†’ Build this (Module 6 Phase D). Directions search + onboarding pack.

### Future Consideration
Re-evaluate OpenClaw in 6+ months when security matures. Potential personal use for Hendra (not team operations). Could potentially connect HMSO data to OpenClaw as read-only knowledge source.

---

## 16) NOTES FOR AI CODING ASSISTANT

Ketika kamu (Claude Code / Cursor) membantu coding project ini:

1. **Selalu baca HMSO_BLUEPRINT.md terlebih dahulu** sebelum menulis kode.
2. **Jangan suggest tech stack alternatif** â€” semua sudah final (lihat Section 2).
3. **Gunakan schema `wa_intel`** untuk semua query Supabase â€” BUKAN schema `public`. Schema `public` adalah HMCS â€” jangan sentuh.
4. **Bahasa kode: TypeScript** â€” konsisten dengan HMCS existing.
5. **Baileys v7** â€” ada breaking changes dari v6. Refer ke https://baileys.wiki dan https://whiskey.so/migrate-latest.
6. **Supabase client**: gunakan `@supabase/supabase-js` v2. Server-side: service_role_key. Dashboard: anon_key + RLS.
7. **AI API calls**: abstrak ke function terpisah agar mudah swap model. Two-tier strategy: GPT-4o-mini for WA messages, premium model (via OpenRouter) for meeting transcripts.
8. **Error handling**: log errors, jangan crash process. Baileys listener HARUS tetap hidup.
9. **Pesan dari Hendra**: selalu check `is_from_hendra` flag. Ini penting untuk classification dan briefing.
10. **Listener = read-only.** Satu-satunya exception: sending daily briefing to Hendra's primary number (1 msg/day).
11. **Delivery to team â†’ via HMCS, NOT WhatsApp bot.** Jangan build WhatsApp sending ke team members. Task notifications harus muncul di HMCS.
12. **HMCS integration**: wa_intel dan HMCS di database yang sama. HMCS bisa query wa_intel tables langsung. Jangan buat foreign keys cross-schema â€” gunakan soft reference.
13. **Full-text search BEFORE vector search.** Implement `to_tsvector('indonesian', ...)` dulu. pgvector hanya jika full-text search tidak cukup.
14. **Ban risk awareness**: Sending 1 msg/day to self = safe. Bulk sending to many numbers = JANGAN.
15. **Source-agnostic pipeline.** Selalu check `source_type` column di messages table. Classifier, briefing, search, dan dashboard harus handle semua source types (`'whatsapp'`, `'meeting'`, future sources).
16. **Meeting transcripts**: Chunk summaries masuk ke `wa_intel.messages` (source_type='meeting'). Full meeting record ada di `wa_intel.meetings`. Jangan confuse keduanya.
17. **Meeting AI model**: Gunakan OpenRouter (premium model) untuk meeting summarization, BUKAN GPT-4o-mini. Meeting chunks bisa 3000-5000 kata â€” butuh model yang kuat.
18. **Classifier prompt harus source-aware**: Meeting chunks bisa mengandung MULTIPLE tasks/directions dalam satu message. Extract semuanya, bukan cuma yang pertama.
